# -*- coding: utf-8 -*-
"""linear_regression_2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1QTwHdmg1hJGHhi6wfCtS8BTT8RhRv1oz
"""

from random import randint
import numpy as np
import matplotlib.pyplot as plt
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import PolynomialFeatures
from sklearn import linear_model
from sklearn.metrics import mean_squared_error
import math 
from math import sqrt

def y_generator(x):
    return math.sin(x)+0.1*np.random.normal(0,1)

print(y_generator(10))

# Commented out IPython magic to ensure Python compatibility.
#Allows a tuple of values to be used as input
f2 = np.vectorize(y_generator)

np.random.seed(100)

#Getting 10 x-values from the x data set
#X_training = np.random.uniform(0,3,10)
X_training = np.sort(np.random.uniform(0,3,10))
#Getting 10 y-values from the y data set that has been computed 
y_training = f2(X_training)

print("----X values for training set----")
print(X_training)

print()
print("----Y values for training set----")
print(y_training)

# %matplotlib inline
#Plots the data points in the training set
#plt.xlim(0,3)
#plt.ylim(0,1.3)
plt.plot(X_training,y_training,'o')
plt.xlabel('X-values for Training Set')
plt.ylabel('Y-values for Training Set')
plt.title('Y vs. X for Training Set')
plt.show()

# Commented out IPython magic to ensure Python compatibility.
X_test = np.random.uniform(0,3,100)
y_test = f2(X_test)

print("----X values for test set----")
print(X_test)

print()
print("----Y values for training set----")
print(y_test)

# %matplotlib inline
#Plots the data points in the test set
#plt.xlim(0,3)
#plt.ylim(0,1.3)
plt.plot(X_test,y_test,'o')
plt.xlabel('X-values for Test Set')
plt.ylabel('Y-values for Test Set')
plt.title('Y vs. X for Test Set')
plt.show()

X_new = np.linspace(0,3)
#print(X_new)

model1 = Pipeline([('poly', PolynomialFeatures(degree=1)),('linear', linear_model.LinearRegression())])
model1 =model1.fit(X_training[:,np.newaxis], y_training[:,np.newaxis])

y_new1 = model1.predict(X_new[:, np.newaxis])


#Plotting the degree 1 fit on the test data
plt.scatter(X_training, y_training)
plt.plot(X_new, y_new1, 'r', label="Fit "+str(1)+ " degree poly")

plt.legend(bbox_to_anchor=(0., 1.02, 1., .102), loc=3,
               ncol=2, mode="expand", borderaxespad=0.)
#plt.xlim(0,3)
#plt.ylim(0,1.3)

plt.show()

model2 = Pipeline([('poly', PolynomialFeatures(degree=2)),('linear', linear_model.LinearRegression())])
model2 =model2.fit(X_training[:,np.newaxis], y_training[:,np.newaxis])

y_new2 = model2.predict(X_new[:, np.newaxis])

#Plotting the degree 1 fit on the test data
plt.scatter(X_training, y_training)
plt.plot(X_new, y_new2, 'r', label="Fit "+str(2)+ " degree poly")
plt.legend(bbox_to_anchor=(0., 1.02, 1., .102), loc=3,
               ncol=2, mode="expand", borderaxespad=0.)
#plt.xlim(0,3)
#plt.ylim(0,1.3)

plt.show()

model9 = Pipeline([('poly', PolynomialFeatures(degree=9)),('linear', linear_model.LinearRegression())])
model9 =model9.fit(X_training[:,np.newaxis], y_training[:,np.newaxis])

y_new9 = model9.predict(X_new[:, np.newaxis])

#Plotting the degree 1 fit on the test data
plt.scatter(X_training, y_training)
plt.plot(X_new, y_new9, 'r', label="Fit "+str(9)+ " degree poly")
plt.legend(bbox_to_anchor=(0., 1.02, 1., .102), loc=3,
               ncol=2, mode="expand", borderaxespad=0.)
#plt.xlim(0,3)
plt.ylim(0,1.3)

plt.show()

#Creating sin function
sin_func = np.sin(X_new)
#plot sin function and gives label for legend
plt.plot(X_new,sin_func,'p:',label='Sin curve')

plot_config=['b', 'r', 'y']
plt.plot(X_training, y_training, 'go', label="Actual")
# 3. Set the polynomial degree to be fitted betwee 1 and 3
d_degree = [1,2,9]
i = 0
for degree in d_degree:
    # 5. Create a fit a polynomial with sk-learn LinearRegression
    model = Pipeline([('poly', PolynomialFeatures(degree=degree)),('linear', linear_model.LinearRegression())])
    model=model.fit(X_training[:,np.newaxis], y_training[:,np.newaxis])
    
    predict_sk=model.predict(X_new[:,np.newaxis])
    
    plt.plot(X_new, predict_sk, plot_config[i], label="Fit "+str(degree)+ " degree poly")
    plt.legend(bbox_to_anchor=(0., 1.02, 1., .102), loc=3,
               ncol=2, mode="expand", borderaxespad=0.)
    #plt.xlim(0,3)
    plt.ylim(0,1.3)
    i = i+1

plt.show()

#Root mean squared error 
y_predictions1 = model1.predict(X_test[:, np.newaxis])
rms1 = sqrt(mean_squared_error(y_test,y_predictions1))
print('Root mean square error for Degree 1')
print(rms1)


#Root mean squared error 
y_predictions2 = model2.predict(X_test[:, np.newaxis])
rms2 = sqrt(mean_squared_error(y_test,y_predictions2))
print('Root mean square error for Degree 2')
print(rms2)


#Root mean squared error 
y_predictions9 = model9.predict(X_test[:, np.newaxis])
rms9 = sqrt(mean_squared_error(y_test,y_predictions9))
print('Root mean square error for Degree 9')
print(rms9)